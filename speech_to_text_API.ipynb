{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "APIKEY=\"####\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install --upgrade google-cloud-speech \n",
    "!pip install --upgrade google-cloud-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.cloud import language\n",
    "\n",
    "import six\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from google.datalab import storage\n",
    "from datalab.context import Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Audio_transformation():\n",
    "  def __init__(self,bucket_name):\n",
    "    \n",
    "    # Instantiates a client\n",
    "    self.speech_client=speech.SpeechClient()\n",
    "    self.language_client = language.LanguageServiceClient()\n",
    "    #Getting access to a certain bucket\n",
    "    self.bucket=storage.Bucket(bucket_name)\n",
    "    #name of the files with certain prefix\n",
    "    \n",
    "    self.lservice = build('language', 'v1beta1', developerKey=APIKEY)\n",
    "    self.file_keys=[]\n",
    "    self.transcripts=[]\n",
    "    #google cloud bucket storage path\n",
    "    self.dir=\"gs://\"+bucket_name\n",
    "    \n",
    "    \n",
    "  #setting the list of files with desired prefix\n",
    "  def get_files_by_prefix(self,prefix):\n",
    "    p=re.compile(prefix)\n",
    "    \n",
    "    for obj in self.bucket.objects():\n",
    "      if(p.match(obj.key)):\n",
    "         self.file_keys.append(obj.key)\n",
    "          \n",
    "  #converting list of Audio to transcript conversions   \n",
    "  def get_transcript(self):\n",
    "    for key in self.file_keys:\n",
    "      url=self.dir+'/'+key\n",
    "      \n",
    "      audio = speech.types.RecognitionAudio(uri=url)\n",
    "      \n",
    "      config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=8000,\n",
    "        language_code='en-US')\n",
    "        \n",
    "      operation = self.speech_client.long_running_recognize(config, audio)\n",
    "      response = operation.result(timeout=90)\n",
    "      quotes=[result.alternatives[0].transcript for result in response.results]\n",
    "      self.transcripts.append(quotes)\n",
    "    \n",
    "  #getting categories assigend to each corpus  \n",
    "  def get_cat(self,text):\n",
    "    if isinstance(text, six.binary_type):\n",
    "      text = text.decode('utf-8')\n",
    "\n",
    "    document = language.types.Document(\n",
    "      content=text.encode('utf-8'),\n",
    "      type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    categories = self.language_client.classify_text(document).categories\n",
    "    return [category.name for category in categories]\n",
    "\n",
    "  #getting series of categories assigend to each transcript\n",
    "  def get_Category(self,quotes):\n",
    "    \n",
    "    texts=[q for q in quotes if len(q.split())>20]\n",
    "    Categories_of_texts=pd.Series(texts,index=texts)\n",
    "    Categories_of_texts=Categories_of_texts.apply(self.get_cat)\n",
    "    return Categories_of_texts\n",
    "  \n",
    "  #getting magnitude assigend to each corpus  \n",
    "  def get_mag(self,quote):\n",
    "    \n",
    "    response = self.lservice.documents().analyzeSentiment(\n",
    "    body={\n",
    "      'document': {\n",
    "         'type': 'PLAIN_TEXT',\n",
    "         'content': quote\n",
    "      }\n",
    "    }).execute()\n",
    "    return response['documentSentiment']['magnitude']\n",
    "\n",
    "  #getting series of magnitude assigend to each transcript\n",
    "  def get_Magnitude(self,quotes):\n",
    "    \n",
    "    texts=[q for q in quotes if len(q.split())>20]\n",
    "    magnitude_of_texts=pd.Series(texts,index=texts)\n",
    "    magnitude_of_texts=magnitude_of_texts.apply(self.get_mag)\n",
    "    return magnitude_of_texts\n",
    "  \n",
    "  \n",
    "  #getting polarity assigend to each corpus  \n",
    "  def get_pol(self,quote):\n",
    "    \n",
    "    response = self.lservice.documents().analyzeSentiment(\n",
    "    body={\n",
    "      'document': {\n",
    "         'type': 'PLAIN_TEXT',\n",
    "         'content': quote\n",
    "      }\n",
    "    }).execute()\n",
    "    return response['documentSentiment']['polarity']\n",
    "\n",
    "  #getting series of polarity assigend to each transcript\n",
    "  def get_Polarity(self,quotes):\n",
    "    \n",
    "    texts=[q for q in quotes if len(q.split())>20]\n",
    "    polarity_of_texts=pd.Series(texts,index=texts)\n",
    "    polarity_of_texts=polarity_of_texts.apply(self.get_pol)\n",
    "    return polarity_of_texts\n",
    "  \n",
    "  def get_ent(self,text):\n",
    "      if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "      document = language.types.Document(\n",
    "      content=text.encode('utf-8'),\n",
    "      type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detect and send native Python encoding to receive correct word offsets.\n",
    "      encoding = language.enums.EncodingType.UTF32\n",
    "      if sys.maxunicode == 65535:\n",
    "        encoding = language.enums.EncodingType.UTF16\n",
    "\n",
    "      result = self.language_client.analyze_entity_sentiment(document, encoding)\n",
    "      entity_type = ('UNKNOWN', 'PERSON', 'LOCATION', 'ORGANIZATION',\n",
    "                   'EVENT', 'WORK_OF_ART', 'CONSUMER_GOOD', 'OTHER')\n",
    "      return set((entity.name,entity_type[entity.type]) for entity in result.entities)\n",
    "\n",
    "  #getting series of entity assigend to each transcrips\n",
    "  def get_Entity(self,quotes):\n",
    "    \n",
    "    texts=[q for q in quotes if len(q.split())>20]\n",
    "    entity_of_texts=pd.Series(texts,index=texts)\n",
    "    entity_of_texts=entity_of_texts.apply(self.get_ent)\n",
    "    return entity_of_texts\n",
    "  \n",
    "  \n",
    "  #creating csv files with each row containing information of copus of an audio file transcript\n",
    "  def generate_analysis_files_per_corpus(self,Category=True,Magnitude=True,Polarity=True,Entity=True):\n",
    "    if(Category==False and Magnitude==False and Polarity==False and Entity==False):\n",
    "            return 0\n",
    "    for i in range(len(self.transcripts)):\n",
    "      df=pd.DataFrame(index=self.transcripts[i])\n",
    "      if(Category):\n",
    "        \n",
    "        Categories_of_texts=self.get_Category(self.transcripts[i])\n",
    "        df[\"Categories\"]=Categories_of_texts\n",
    "        \n",
    "      if(Magnitude):\n",
    "        magnitude_of_texts=self.get_Magnitude(self.transcripts[i])\n",
    "        df['Magnitude']=magnitude_of_texts\n",
    "        \n",
    "      if(Polarity):\n",
    "        polarity_of_texts=self.get_Polarity(self.transcripts[i])\n",
    "        df['Polarity']=polarity_of_texts\n",
    "        \n",
    "      if(Entity):\n",
    "        entity_of_texts=self.get_Entity(self.transcripts[i])\n",
    "        df['Entity']=entity_of_texts\n",
    "        \n",
    "      name_of_file='Per_corpus_analysis'+self.file_keys[i][24:30]+'.csv'\n",
    "      df.to_csv(name_of_file)\n",
    "    \n",
    "  #creating csv files with single row containing information of  an audio file transcript\n",
    "  def generate_analysis_files_per_Audiofile(self,Category=True,Magnitude=True,Polarity=True,Entity=True):\n",
    "    if(Category==False and Magnitude==False and Polarity==False and Entity==False):\n",
    "            return 0\n",
    "    for i in range(len(self.transcripts)):\n",
    "        texts=[q for q in self.transcripts[i] if len(q.split())>20]\n",
    "        text=' '.join(texts)\n",
    "        df=pd.DataFrame(index=[text])\n",
    "        if(Category):\n",
    "            Categories_of_texts=self.get_cat(text)\n",
    "            df[\"Categories\"]=Categories_of_texts\n",
    "            \n",
    "        if(Magnitude):\n",
    "          magnitude_of_texts=self.get_mag(text)\n",
    "          df['Magnitude']=magnitude_of_texts\n",
    "        if(Polarity):\n",
    "          polarity_of_texts=self.get_pol(text)\n",
    "          df['Polarity']=polarity_of_texts\n",
    "        \n",
    "        if(Entity):\n",
    "          \n",
    "          df['Entity']=[self.get_ent(text)]\n",
    "          \n",
    "        name_of_file='full_Audio_analysis'+self.file_keys[i][24:30]+'.csv'\n",
    "        df.to_csv(name_of_file)\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "    \n",
    "      \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
